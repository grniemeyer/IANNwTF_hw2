{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMX2vfapC1jhvEiCx0L5hE/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/grniemeyer/IANNwTF_hw2/blob/main/PlayingWithMnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "2vDAL23ouiKA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c4fb4bca-63be-47f8-dcda-8d4774c4fb25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tfds.core.DatasetInfo(\n",
            "    name='mnist',\n",
            "    full_name='mnist/3.0.1',\n",
            "    description=\"\"\"\n",
            "    The MNIST database of handwritten digits.\n",
            "    \"\"\",\n",
            "    homepage='http://yann.lecun.com/exdb/mnist/',\n",
            "    data_dir='/root/tensorflow_datasets/mnist/3.0.1',\n",
            "    file_format=tfrecord,\n",
            "    download_size=11.06 MiB,\n",
            "    dataset_size=21.00 MiB,\n",
            "    features=FeaturesDict({\n",
            "        'image': Image(shape=(28, 28, 1), dtype=uint8),\n",
            "        'label': ClassLabel(shape=(), dtype=int64, num_classes=10),\n",
            "    }),\n",
            "    supervised_keys=('image', 'label'),\n",
            "    disable_shuffling=False,\n",
            "    splits={\n",
            "        'test': <SplitInfo num_examples=10000, num_shards=1>,\n",
            "        'train': <SplitInfo num_examples=60000, num_shards=1>,\n",
            "    },\n",
            "    citation=\"\"\"@article{lecun2010mnist,\n",
            "      title={MNIST handwritten digit database},\n",
            "      author={LeCun, Yann and Cortes, Corinna and Burges, CJ},\n",
            "      journal={ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist},\n",
            "      volume={2},\n",
            "      year={2010}\n",
            "    }\"\"\",\n",
            ")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 900x900 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[-1. -1. -1. ... -1. -1. -1.]\n",
            " [-1. -1. -1. ... -1. -1. -1.]\n",
            " [-1. -1. -1. ... -1. -1. -1.]\n",
            " [-1. -1. -1. ... -1. -1. -1.]], shape=(4, 784), dtype=float32) tf.Tensor(\n",
            "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]], shape=(4, 10), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# Data prep\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# tensorflow = (data) pipeline, factory\n",
        "# tensorflow tensor like array\n",
        "\n",
        "\n",
        "(train_ds,test_ds), ds_info = tfds.load('mnist', split=['train', 'test'], with_info=True)\n",
        "# print(ds_info)\n",
        "# tfds.show_examples(train_ds, ds_info)\n",
        "\n",
        "\n",
        "# remember order for exam!!\n",
        "ds = train_ds.map(lambda feature_dict: (feature_dict[\"image\"], feature_dict[\"label\"])) # ectract images and features\n",
        "ds = ds.map(lambda image, label: (tf.reshape(image, (-1,)), label)) # flatten images, pass on labels\n",
        "ds = ds.map(lambda image, label: ((tf.cast(image, tf.float32) / 128.0) -1, label)) # normalize images and pass on\n",
        "ds = ds.map(lambda image, label: (image, tf.one_hot(label, depth=10))) # one hottify\n",
        "ds = ds.shuffle(1024).batch(4) # create small buffer(9 pieces of choc bzw. 1024) in between for shuffling then batch; tf's batch operation takes care of the remainder shape\n",
        "trains_ds = ds.prefetch(4) # parralelisation: 2nd buffer that has always shuffled (prefetched) batches availabe. Shuffling & prefetching takes lot of memory\n",
        "\n",
        "\n",
        "for x, y in ds.take(1):\n",
        "  print(x, y)\n",
        "\n",
        "\n",
        "# • How many training/test images are there?\n",
        "# - 'test' 10,000, train' 60,000\n",
        "# • What’s the image shape?\n",
        "# - (28, 28, 1)\n",
        "# • What range are pixel values in?\n",
        "# - In grayscale images, a pixel value of 0 represents black, and 255 represents white"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.3 Building a DNN with TF\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "class MyDeepNN():\n",
        "  def __init__(self):\n",
        "    super(MyDeepNN, self).__init__()\n",
        "    self.dense1 = tf.keras.layers.Dense(256, activation=tf.nn.relu)\n",
        "    self.dense2 = tf.keras.layers.Dense(256, activation=tf.nn.relu)\n",
        "    self.out = tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "\n",
        "  @tf.function # decorator -> adds special functionalities to function below\n",
        "  def call(self, inputs):\n",
        "    x = self.dense1(inputs)\n",
        "    x = self.dense2(x)\n",
        "    y = self.out(x)\n",
        "    return y\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "f9CP2B7hFHRP"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.4 Training the Network\n",
        "\n",
        "\n",
        "# define hyperparameters\n",
        "nr_epochs = 10\n",
        "learning_rate = 0.1\n",
        "\n",
        "# initialize stuff\n",
        "mymodel = MyDeepNN()\n",
        "cross_entropy_loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "opti = tf.keras.optimizers.SGD(learning_rate)\n",
        "\n",
        "# lists (for viualization later)\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "test_accuracies = []\n",
        "\n",
        "# test before sending through NN, for comparison afterwards\n",
        "#test_loss, test_accuracy = test(mymodel, train_ds, cross_entropy_loss)\n",
        "#test_losses_append(test_loss)\n",
        "#test_accuracies.append(test_accuracy)\n",
        "\n",
        "# test with train_ds before training NN\n",
        "#train_loss,_ = test(mymodel, train_ds, cross_entropy_loss)\n",
        "#train_losses.append(train_loss)\n",
        "\n",
        "\n",
        "# tests on 1 input-target pair\n",
        "def train_step(model, input, target, loss_function, optimizer):\n",
        "  with tf.GradientTape() as tape:\n",
        "    prediction = model(input)\n",
        "    loss = loss_function(target, prediction)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables) # trainable_variables = weights?\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "  return loss\n",
        "\n",
        "\n",
        "def test(model, test_ds, loss_function):\n",
        "  test_accuracy_aggregator = []\n",
        "  test_loss_aggregator = []\n",
        "\n",
        "  for (image, target) in test_ds:\n",
        "    prediction = model(image)\n",
        "    sample_test_loss = loss_function(target, prediction)\n",
        "    sample_test_accuracy = np.argmax(target, axis=1) == np.armay(prediction, axis=1)\n",
        "    sample_test_accuracy = np.mean(sample_test_accuracy)\n",
        "    test_loss_aggregator.append(sample_test_loss.numpy())\n",
        "    test_accuracy_aggregator.append(np.mean(sample_test_accuracy))# double averaging??\n",
        "\n",
        "  test_loss = tf.reduce_mean(test_loss_aggregator)\n",
        "  test_accuracy = tf.reduce_mean(test_accuracy_aggregator)\n",
        "\n",
        "  return test_loss, test_accuracy\n",
        "\n",
        "\n",
        "\n",
        "for epoch in range(nr_epochs):\n",
        "#  print(f\"epoch: {str(epoch)} with accuracy {test_accuracies[-1]}\") # starting with last element in test_accuracies\n",
        "\n",
        "  # training\n",
        "  epoch_losses = []\n",
        "  for image, label in train_ds:\n",
        "    train_loss = train_step(mymodel, image, label, cross_entropy_loss, opti)\n",
        "    epoch_losses.append(train_loss)\n",
        "\n",
        "  # track training loss\n",
        "  train_losses.append(tf.reduce_mean(epoch_losses)) #take the mean\n",
        "\n",
        "  # testing (track test loss and test accuracy)\n",
        "  test_loss, test_accuracy = test(mymodel,test_ds, cross_entropy_loss)\n",
        "  test_losses.append(test_loss)\n",
        "  test_accuracies.append(test_accuracy)\n"
      ],
      "metadata": {
        "id": "9ETX31V2e6mp",
        "outputId": "b4e9e129-3480-4b0b-bb51-fcdc954cb3d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-e6480b76bc7d>\u001b[0m in \u001b[0;36m<cell line: 68>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m   \u001b[0mepoch_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmymodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopti\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0mepoch_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-56-e6480b76bc7d>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(model, input, target, loss_function, optimizer)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m   \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# trainable_variables = weights?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'MyDeepNN' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Creation via Subclassing from tf.keras.Model\n",
        "\n",
        "#inherit from keras.Model\n",
        "class MLP_Model(self, layer_size):\n",
        "  def __init__(self, layer_size, output_size=10):\n",
        "    super().__init__()\n",
        "    self.layers = []\n",
        "    #layer_size e.g.[256, 256]\n",
        "\n",
        "    for layer_size in layer_sizes:\n",
        "      new_layer = tf.keras.layers.Dense(units=layer_size, activation=\"sigmoid\")\n",
        "      self.layers.append(new_layer)\n",
        "    self.output_layer = tf.keras.layers.Dense(units=output_size, activation=\"softmax\") # output layer ist deshalb specified seperately bc we need different activation function\n",
        "\n",
        "  def call(self, x):\n",
        "    for layer in self.layers:\n",
        "      x = layer(x) # call layer on input\n",
        "    y = self.output.layer(x)\n",
        "    return y"
      ],
      "metadata": {
        "id": "tK6rhidICYz5",
        "outputId": "95c47402-1f09-4143-ee8d-ca19e13b73d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-8c8c162bb783>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Model Creation via Subclassing from tf.keras.Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#inherit from keras.Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tf'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "\n",
        "EPOCHS = 10\n",
        "\n",
        "model = MLP_Model(layer_sizes=[256, 256])\n",
        "cce = tf.keras.CategoricalCrossEntropy()\n",
        "optimizer = tf.keras.optimizers.legacy.SGD() # stochastic gradient as optimizer\n",
        "ds = ds # does nothing, just as reminder from above\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  losses = []\n",
        "\n",
        "  for x, target in ds:\n",
        "    with tf.GradientTape() as tape: # context manager\n",
        "      pred = model(x)\n",
        "      loss = cce(target, pred)\n",
        "    gradients = tape.gradient(loss, model.varibles) # calculate gradient outside of GradientTape, otherwis it calculates gradient of gradient (memory!!, rare exceptions)\n",
        "    optimizer.appy_gradients(zip(gradients, model.variables))\n",
        "    losses.append(loss.numpy())\n",
        "  print(np.mean(losses))"
      ],
      "metadata": {
        "id": "zD6Q6lWMFsaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pmP01ImfBLkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TF Session 20.11.23 - custom gradient"
      ],
      "metadata": {
        "id": "sdpnrenyBM85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# custom gradient\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "sample_input = tf.random.uniform(shape = (4,2), dtype=np.float32)\n",
        "\n",
        "# @ - indicates a decorater function\n",
        "\n",
        "#tf.custom_gradient()\n",
        "\n",
        "\n",
        "# writing own sigmoid\n",
        "\n",
        "@tf.custom_gradient\n",
        "def my_sigmoid(x):\n",
        "  sigmoid_res = 1/1+tf.exp(-x)\n",
        "  def grad(upstream):\n",
        "    diag_of_jacobian = sigmoid_res*(1-sigmoid_res)\n",
        "    downstream = upstream*diag_of_jacobian\n",
        "  return sigmoid_res, grad"
      ],
      "metadata": {
        "id": "3ujXkH9WBMD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# writing own ReLu\n",
        "\n",
        "# hint: use with tf.where\n",
        "\n",
        "def my_relu(x):\n",
        "  relus = tf.where(x>0, x, tf.zeros_like(x))\n",
        "\n",
        "  def grad(upstream):\n",
        "    d_dx = tf.where(x>0, tf.ones_like(x), tf.zeros_like(x))\n",
        "    downstream = upstream*d_dx\n",
        "    return downstream\n",
        "  return relus, grad"
      ],
      "metadata": {
        "id": "EygSrPr_E-p0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# explain gradientTape\n",
        "\n",
        "sample_input = tf.Variable(initial_value=sample_input)\n",
        "with tf.GradientTape(persistent = True) as tape:\n",
        "  my_relu_act = my_relu(sample_input)\n",
        "#  tf_relu_act = tf.nn.relu(sample_input) # common tf relu for comparison (however not possible to compute together, too much memory asked, so not possible or tell to be \"persistent\", buuut can crash your memory) 1.0\n",
        "#grads_tf_relu = tape.gradient(tf_relu_act, [sample_input]) # 2.0\n",
        "grads_my_relu = tape.gradient(my_relu_act, [sample_input])\n",
        "print(grads_my_relu)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "b-OlTjb3IwLl",
        "outputId": "150f7631-6a92-4d82-f6b1-6c726c8d1285"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-56a5f5889f6b>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#  tf_relu_act = tf.nn.relu(sample_input) # common tf relu for comparison (however not possible to compute together, too much memory asked, so not possible or tell to be \"persistent\", buuut can crash your memory) 1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#grads_tf_relu = tape.gradient(tf_relu_act, [sample_input]) # 2.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mgrads_my_relu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_relu_act\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msample_input\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_my_relu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mflat_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1033\u001b[0;31m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbackprop_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIsTrainable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1034\u001b[0m         logging.vlog(\n\u001b[1;32m   1035\u001b[0m             \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"The dtype of the target tensor must be \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/backprop_util.py\u001b[0m in \u001b[0;36mIsTrainable\u001b[0;34m(tensor_or_dtype)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_or_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m   \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m   trainable_dtypes = [dtypes.float16, dtypes.float32, dtypes.float64,\n\u001b[1;32m     61\u001b[0m                       \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplex64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplex128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/dtypes.py\u001b[0m in \u001b[0;36mas_dtype\u001b[0;34m(type_value)\u001b[0m\n\u001b[1;32m    856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_INTERN_TABLE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 858\u001b[0;31m   raise TypeError(f\"Cannot convert the argument `type_value`: {type_value!r} \"\n\u001b[0m\u001b[1;32m    859\u001b[0m                   \"to a TensorFlow DType.\")\n",
            "\u001b[0;31mTypeError\u001b[0m: Cannot convert the argument `type_value`: <function my_relu.<locals>.grad at 0x79732ea3a950> to a TensorFlow DType."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = []\n",
        "sample_input = tf.Variable(initial_value=tf.random.uniform(shape=(4,3)))\n",
        "\n",
        "@tf.function # saves time??, however only for tensorflow code, NO classical python code (print(), .append(), etc)\n",
        "def some_tf_loop():\n",
        "  for step in tf.range(10):\n",
        "    inputs = sample_input[step,:,:]\n",
        "  with tf.GradientTape(persistent = True) as tape:\n",
        "    my_relu_act = my_relu(sample_input)\n",
        "    tf_relu_act = tf.nn.relu(sample_input)\n",
        "  grads_tf_relu = tape.gradient(tf_relu_act, [sample_input])\n",
        "  grads_my_relu = tape.gradient(my_relu_act, [sample_input])\n",
        "  del tape\n",
        "\n",
        "print(grads_tf_relu, grads_my_relu)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "vp_qX_BLL_y7",
        "outputId": "d2e0e565-7c2f-4c16-ffe4-3b705378583c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-edba86ded4e5>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_tf_relu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads_my_relu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'grads_tf_relu' is not defined"
          ]
        }
      ]
    }
  ]
}